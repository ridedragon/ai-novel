# AI 小说创作系统全维度调试报告：架构瓶颈、竞态冲突与性能优化路线

## 1. 绪论

### 1.1 系统背景

“AI小说创作系统”是一个高度集成化、流程化的文学创作平台。它通过 React 实现响应式 UI，利用 IndexedDB (idb-keyval) 处理大规模本地存储，并深度集成 OpenAI 兼容接口实现自动化创作。系统的核心价值在于其“长文模式”——通过层级化的摘要总结（小总结、大总结）来突破 AI 上下文窗口的限制，从而支撑超长篇小说的逻辑连贯性。

### 1.2 故障背景

随着用户创作规模的不断扩大（单本小说章节突破 200 章，字数突破百万），系统暴露出了一系列严重的稳定性与性能问题。用户反馈的 5 个核心问题（性能卡死、章节复活、工作流残留、总结无法中止、排序混乱）并非孤立存在，而是相互关联的架构设计副作用。

### 1.3 调试方法论

本报告采用“系统性溯源法”进行诊断。通过对 [`src/App.tsx`](src/App.tsx)、[`src/utils/storage.ts`](src/utils/storage.ts)、[`src/utils/SummaryManager.ts`](src/utils/SummaryManager.ts) 以及工作流组件的源码进行多轮静态扫描，还原数据在“内存-存储-网络-UI”四个维度的流动轨迹，从而精准定位故障根因。

---

## 2. 性能瓶颈分析：80秒“冰封”背后的技术细节

### 2.1 问题描述

用户在操作包含 200 章以上书籍时，点击生成或移动章节会产生长达 80 秒的无响应（卡死）。日志显示瓶颈出现在 [`applyRegexToText`](src/App.tsx:1865) 且文本长度高达 22 万字符。

### 2.2 核心根因：同步正则引擎与数据爆炸的碰撞

#### 2.2.1 递归上下文收集逻辑的副作用

在 [`src/App.tsx:4945`](src/App.tsx:4945) 的 `getChapterContext` 中，系统为了保证长文逻辑连贯，采取了如下策略：

1. **总结层级累加**：收集所有结束位置早于当前章节的“小总结”和“大总结”。
2. **增量细节补全**：获取最近几章的原文内容。

**数据模型分析**：
对于 200 章的小说：

* 小总结（每 3 章一个）：约 66 个，均长 500 字 $\approx$ 33,000 字。
* 大总结（每 6 章一个）：约 33 个，均长 1000 字 $\approx$ 26,000 字。
* 全书正则前置处理后的总上下文可能瞬间突破 **250,000 字符**。

#### 2.2.2 同步执行链的阻塞机制

故障函数 [`processTextWithRegex`](src/App.tsx:1895) 逻辑如下：

```typescript
const processTextWithRegex = async (text: string, scripts: RegexScript[], type: 'input' | 'output') => {
    if (!text) return text
    const relevantScripts = scripts.filter(s => !s.disabled && s.placement.includes(type === 'input' ? 1 : 2))
    return await applyRegexToText(text, relevantScripts) // 异步调用同步处理
}
```

进入 [`applyRegexToText`](src/App.tsx:1865)：

```typescript
for (const script of scripts) {
    if (Date.now() - startTime > 50) {
        await new Promise(resolve => setTimeout(resolve, 0));
    }
    // 原子性的耗时操作
    processed = processed.replace(regex, script.replaceString)
}
```

**技术性误区**：
这里的 `setTimeout` 仅在循环迭代之间让出主线程。然而，JavaScript 引擎执行 `string.replace(regex, ...)` 的过程是**同步且不可中断**的。
当处理一个 22 万字的超长字符串时，如果正则表达式包含复杂的贪婪匹配或回溯逻辑，单个 `replace` 调用的执行时长可能就超过了 5 秒。系统配置了多个全局正则脚本，累加起来导致主线程被死锁 80 秒。在这一期间，React 无法执行任何渲染（Rendering），浏览器无法处理用户输入，整个页面呈现“假死”状态。

### 2.3 状态更新与渲染性能降级 (问题 3)

[`App.tsx` 的 `setNovels`](src/App.tsx:1095) 存在性能损耗。尽管使用了 `React.memo` 包装 [`ChapterSidebarItem`](src/App.tsx:857)，但在 200 多个章节的情况下，每一次正文生成触发的状态更新，都会导致 React 在虚拟 DOM 树中进行大规模对比。
由于 `novels` 数据结构极其深重（包含全量正文、版本、设定），深层对比（Reconciliation）的开销呈指数级上升。

---

## 3. 逻辑竞态诊断：章节删除后的“亡灵复活”现象

### 3.1 问题描述

用户反馈：如果在 AI 创作正文时删除章节，过一会被删除的章节会重新出现（复活）。

### 3.2 根因：异步闭包（Stale Closure）与自愈逻辑的碰撞

#### 3.2.1 异步快照的滞后性

在 [`src/App.tsx:5470`](src/App.tsx:5470) 的 `autoWriteLoop` 递归循环中，系统执行以下操作：

1. **捕获快照**：发起异步请求前，通过 `novelsRef.current` 捕获当时的章节列表。
2. **等待网络**：执行网络请求（通常耗时 10-60 秒）。
3. **回写状态**：请求返回后，调用 `setNovels`。

#### 3.2.2 亡灵复活的执行路径

假设用户在 AI 请求期间执行了删除章节 $X$ 的操作：

1. **物理删除**：`handleDeleteChapter` 执行成功，数据库和 React 状态中章节 $X$ 已消失。
2. **AI 返回**：`autoWriteLoop` 携带的是包含章节 $X$ 的旧列表副本。
3. **回写冲突**：在 `autoWriteLoop` 内部的逻辑中（[`App.tsx:5813`](src/App.tsx:5813)），它会使用 `map` 遍历旧副本进行内容更新。
4. **自愈逻辑引发的“复活”**：
    在 [`App.tsx:5537`](src/App.tsx:5537) 的占位逻辑中：

    ```typescript
    if (!existingById && !existingByTitle) {
        // 认为章节意外丢失，重新创建一个占位对象并 Push 进列表
        newChapters.push({ id: batchItem.id, title: batchItem.title, ... }) 
    }
    ```

    当异步回调触发时，它发现主状态中缺少该章节，误判为“数据丢失”，从而重新创建并写回了数据库。

---

## 4. 工作流状态管理故障：重置失效与残留

### 4.1 问题描述

即使重置了工作流，运行到正文创作节点时仍会发出上一次未完成的请求。

### 4.2 根因：节点私有数据清理不彻底

在 [`src/components/WorkflowEditor.tsx:2700`](src/components/WorkflowEditor.tsx:2700) 的 `resetWorkflowStatus` 中，代码仅执行了如下操作：

```typescript
data: {
  status: 'pending',
  outputEntries: []
}
```

**技术漏洞**：
正文创作节点（Chapter Node）在执行期间会产生一些**持久化动态关联**，例如 `targetVolumeId`。
当 `AutoWriteEngine` 被触发时，它会读取节点数据。如果重置时没有清理 `targetVolumeId`，引擎会认为它是要“继续完成”上一个分卷中的未竟任务。
叠加 [`WorkflowEditor.tsx:2100`](src/components/WorkflowEditor.tsx:2100) 的自愈逻辑：

```typescript
if (!currentSet) {
    // 自动寻找最后一次有效的大纲集
    currentSet = fallbackSet;
}
```

这种过度设计的“鲁棒性”在此时反而成了累赘，导致用户无法通过重置彻底切断历史状态。

---

## 5. 异步生命周期故障：总结请求无法终止

### 5.1 问题描述

点击“终止工作流”无法取消已经发起的总结请求。

### 5.2 根因分析：孤儿 Promise (Orphan Promises)

在 [`src/utils/SummaryManager.ts:156`](src/utils/SummaryManager.ts:156) 的 `checkAndGenerateSummary` 原始实现中，函数没有接收并绑定 `AbortSignal`。

**执行链断裂过程**：

1. 用户点击“终止”。
2. 工作流主进程的 `autoWriteAbortController.abort()` 被调用，主循环停止。
3. 然而，在此之前由 `onChapterComplete` 钩子触发的总结生成子任务（异步调用）已经处于运行状态。
4. 由于 `checkAndGenerateSummary` 是“发射后不管”（Fire-and-forget）模式，它内部的 OpenAI 请求会一直等待直到超时或成功。
5. 请求成功后，由于其回调依然持有闭包状态，它会强行执行 `setNovels`，导致总结条目在工作流停止后依然被插入目录。

---

## 6. 新发现故障：总结排序异常与分卷丢失

### 6.1 总结排序算法缺陷

用户反馈截图中显示“🔹小总结”出现在了“第一章”之前。
**成因**：[`SummaryManager.ts:25`](src/utils/SummaryManager.ts:25) 的 `sortChapters` 函数依赖于 `summaryRange` 字段。
如果生成的总结章节带有异常的 Range 格式（例如：`0-0` 或非法字符），解析出来的 `endIndex` 会变成 0 或 NaN。
在排序对比逻辑中：

```typescript
const storyOrder = index + 1;
const matchedSummaries = summariesByEndIndex.get(storyOrder);
```

如果索引匹配失败，这些总结会被推到算法的“孤立处理”环节（line 112），最终被无序地 Push 进数组前端或末尾。

### 6.2 工作流分卷名称丢失 (Data Healing 冲突)

**原因**：[`App.tsx:1142`](src/App.tsx:1142) 的 `Data Healing` 逻辑试图从工作流配置中找回分卷名称。
但在 [`WorkflowEditor.tsx:1832`](src/components/WorkflowEditor.tsx:1832) 中创建分卷时，由于采用了 `Date.now()` 作为 ID 生成器，在极端高频操作下可能产生 ID 重复或冲突。
当 `Data Healing` 执行 ID 查找时，如果发现 ID 已存在但名称为空（来自 stripped novel 的 Skeleton 状态），它会覆盖掉刚刚创建的有效分卷名称。

---

## 7. 系统性修复与优化建议

### 7.1 性能优化：Web Worker 正则分片

必须将正则清洗异步化。由于 `replace` 本身是 CPU 密集型任务，建议引入 Web Worker 专门处理：

```typescript
// 推荐的逻辑分片方案
async function applyRegexInChunks(text, scripts) {
    let result = text;
    for (const script of scripts) {
        // 将文本切分为 20000 字一段，逐段处理，每段处理完 yield 一次
        const chunks = result.match(/.{1,20000}/gs) || [];
        const processedChunks = [];
        for (const chunk of chunks) {
            processedChunks.push(chunk.replace(new RegExp(script.findRegex, 'g'), script.replaceString));
            await new Promise(r => setTimeout(resolve, 0)); // 真正的 UI 呼吸
        }
        result = processedChunks.join('');
    }
    return result;
}
```

### 7.2 逻辑修复：已删除章节的“逻辑屏障”

在 `App.tsx` 中引入全局已删除 ID 集合，并在 `setNovels` 中建立强制阻断：

```typescript
const [deletedIds] = useState(new Set());

// 在 handleChapterDelete 时写入 deletedIds
// 在 setNovels 的 Functional Update 内部执行强制过滤
_setNovels(prev => {
    const next = value(prev);
    return next.map(novel => ({
        ...novel,
        chapters: novel.chapters.filter(c => !deletedIds.has(c.id))
    }));
});
```

### 7.3 生命周期修复：全链路 AbortSignal 传递

确保 `SummaryManager` 彻底打通中止信号链路。

1. 在 [`src/utils/SummaryManager.ts:156`](src/utils/SummaryManager.ts:156) 及其子函数中增加 `signal?: AbortSignal` 参数。
2. 在所有 OpenAI 客户端调用处（line 327 等）绑定 `{ signal }`。
3. 在 `App.tsx` 中维护一个 `summaryAbortControllerRef`，在工作流停止或组件卸载时统一调用 `abort()`。

---

## 8. 结论

本报告分析的五个核心问题，本质上是系统在从小规模创作向超长篇、大规模自动化创作演进过程中的“成长痛”。
核心瓶颈在于：

1. **单线程处理大数据**导致的性能冰封。
2. **异步快照不一致**导致的逻辑竞态。
3. **任务信号链路断层**导致的控制失灵。

通过实施上述建议的“正则分片”、“逻辑屏障”以及“全链路信号透传”，系统将具备支撑万章级规模创作的架构底座，彻底解决卡顿与状态异常问题。
